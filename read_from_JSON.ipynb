{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import JSONDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_JSON_as_list(filename):\n",
    "    def parse_pairs(pairs):\n",
    "        return pairs\n",
    "\n",
    "    decoder = JSONDecoder(object_pairs_hook=parse_pairs)\n",
    "    with open(filename) as json_file:\n",
    "        file_content = json_file.read()\n",
    "        data = decoder.decode(file_content)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_JSON_as_list('./JSON/mental_imagery_extended.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all object instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_objects(json_as_list):\n",
    "    # first get the objects outside of groups\n",
    "    objects = json_as_list[1][1]\n",
    "    \n",
    "    key_to_pos_dict = {}\n",
    "    for ind, elem in enumerate(json_as_list):\n",
    "        key_to_pos_dict[elem[0]] = ind\n",
    "        \n",
    "    groups = json_as_list[key_to_pos_dict['groups']][1]\n",
    "    \n",
    "    for group in groups:\n",
    "        for obj in group[1][1][1]:\n",
    "            # add the group name to the object, otherwise there might be duplicate object names\n",
    "            # also added in connections\n",
    "            obj[1][0] = ('name', group[0] + \".\" + obj[1][0][1])\n",
    "            objects.append(obj)\n",
    "            \n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = get_all_objects(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cedar.dynamics.NeuralField \n",
      "\n",
      "[('name', 'Above Memory'), ('activation as output', 'false'), ('discrete metric (workaround)', 'false'), ('update stepIcon according to output', 'true'), ('threshold for updating the stepIcon', '0.80000000000000004'), ('dimensionality', '0'), ('sizes', ''), ('time scale', '100'), ('resting level', '-5'), ('input noise gain', '0.10000000000000001'), ('sigmoid', [('type', 'cedar.aux.math.AbsSigmoid'), ('threshold', '0'), ('beta', '100')]), ('global inhibition', '-0.01'), ('lateral kernels', [('cedar.aux.kernel.Box', [('dimensionality', '1'), ('anchor', ['0']), ('amplitude', '6.0999999999999996'), ('widths', ['2'])])]), ('lateral kernel convolution', [('borderType', 'Zero'), ('mode', 'Same'), ('engine', [('type', 'cedar.aux.conv.OpenCV')]), ('alternate even kernel center', 'false')]), ('noise correlation kernel', [('dimensionality', '1'), ('anchor', ['0']), ('amplitude', '0'), ('sigmas', ['3']), ('normalize', 'true'), ('shifts', ['0']), ('limit', '5')]), ('comments', '')] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' data[1][1] has the value for 'steps' --> a list of the different objects \n",
    "    (except for the ones in groups)\n",
    "    e.g. data[1][1][0] is a NeuralField, its first element is the type of object,\n",
    "    i.e. in this case the string 'cedar.dynamics.NeuralField', its second element\n",
    "    contains the parameters and their values\n",
    "'''\n",
    "print(objects[0][0], \"\\n\")\n",
    "\n",
    "print(objects[0][1], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cedar.dynamics.NeuralField: 90\n",
      "Number of cedar.processing.sources.Boost: 23\n",
      "Number of cedar.processing.ComponentMultiply: 52\n",
      "Number of cedar.processing.sources.ConstMatrix: 8\n",
      "Number of cedar.processing.steps.Convolution: 4\n",
      "Number of cedar.processing.Flip: 4\n",
      "Number of cedar.processing.sources.GaussInput: 16\n",
      "Number of cedar.processing.Projection: 38\n",
      "Number of cedar.processing.sources.SpatialTemplate: 24\n",
      "Number of cedar.processing.StaticGain: 166\n"
     ]
    }
   ],
   "source": [
    "# check if I have all objects now by checking if the numbers are the same as\n",
    "# in the json file\n",
    "object_counts = {}\n",
    "\n",
    "for obj in objects:\n",
    "    if obj[0] not in object_counts.keys():\n",
    "        object_counts[obj[0]] = 1\n",
    "    else:\n",
    "        object_counts[obj[0]] += 1\n",
    "        \n",
    "for key in object_counts:\n",
    "    print('Number of %s: %i' %(key, object_counts[key]))\n",
    "\n",
    "# --> Numbers check out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all connections\n",
    "For the groups the connections to and from the input nodes of the groups and output nodes of the groups have to be handled seperately, since these should be replaced by direct connections between the instances.\n",
    "\n",
    "The names of the input and output nodes for groups are in the group element \"connectors\". If they have the value \"true\" they are input nodes, if the have the value \"false\" they are output nodes. In connections to input nodes of a group the target name is of the form: group_name.input_node_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_group_name(group_connection, group_name):\n",
    "    new_group_connection = [('source', group_name + \".\" + group_connection[0][1]),\n",
    "                            ('target', group_name + \".\" + group_connection[1][1])]\n",
    "    return new_group_connection\n",
    "\n",
    "\n",
    "def find_connector_connections(connectors, \n",
    "                               outside_group_connections, \n",
    "                               inside_group_connections,\n",
    "                               output_nodes=True):\n",
    "    ''' outside_group_connections list of connections, inside_group_connections\n",
    "        dictionary of list of connections per group.\n",
    "    \n",
    "        output_nodes True means that the connectors in the list are output\n",
    "        nodes of their groups, if it is False they are input nodes.\n",
    "        Elements in connectors should be of the form: \n",
    "        (group_name, connector_name)\n",
    "    '''\n",
    "    connector_connections = {}\n",
    "\n",
    "    for connector in connectors:\n",
    "        connector_connections[connector] = {'input connections': [], \n",
    "                          'output connections': []}\n",
    "\n",
    "        if output_nodes:\n",
    "            source_string = connector[0] + \".\" + connector[1]\n",
    "            target_string = connector[0] + \".\" + connector[1] + \".input\"\n",
    "        else:\n",
    "            source_string = connector[0] + \".\" + connector[1] + \".output\"\n",
    "            target_string = connector[0] + \".\" + connector[1] \n",
    "\n",
    "        # need the \":\", otherwise removing and iterating at the same time leads to \n",
    "        # weird results\n",
    "        for connection in outside_group_connections[:]:\n",
    "            if connection[0][1] == source_string:\n",
    "                connector_connections[connector]['output connections'].append(connection) \n",
    "                outside_group_connections.remove(connection)\n",
    "            elif connection[1][1] == target_string:\n",
    "                connector_connections[connector]['input connections'].append(connection)\n",
    "                outside_group_connections.remove(connection)\n",
    "\n",
    "        for connection in inside_group_connections[connector[0]][:]:\n",
    "            if connection[1][1] == target_string:\n",
    "                connector_connections[connector]['input connections'].append(connection)\n",
    "                inside_group_connections[connector[0]].remove(connection)\n",
    "            elif connection[0][1] == source_string:\n",
    "                connector_connections[connector]['output connections'].append(connection)\n",
    "                inside_group_connections[connector[0]].remove(connection)\n",
    "                \n",
    "    return connector_connections\n",
    "\n",
    "\n",
    "def replace_middle_connection(middle_connection_dict):\n",
    "    ''' takes as input a dictionary with input connections to a node and \n",
    "        output connections from the node and creates new connections substituting\n",
    "        the middle node and connecting the inputs from the input nodes and the \n",
    "        outputs from the output nodes directly.\n",
    "    '''\n",
    "    # each input has to be connected to each output\n",
    "    connections_list = []\n",
    "\n",
    "    # go through all inputs\n",
    "    for inp_connection in middle_connection_dict['input connections']:\n",
    "        # source at position 0\n",
    "        source = inp_connection[0]\n",
    "        # go through all outputs\n",
    "        for out_connection in middle_connection_dict['output connections']:\n",
    "            # target at position 1\n",
    "            target = out_connection[1]\n",
    "            connections_list.append([source, target])\n",
    "\n",
    "    return connections_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_connections(json_as_list):\n",
    "    \n",
    "    key_to_pos_dict = {}\n",
    "    for ind, elem in enumerate(data):\n",
    "        key_to_pos_dict[elem[0]] = ind\n",
    "        \n",
    "    connections_outside_groups = json_as_list[key_to_pos_dict[\"connections\"]][1]\n",
    "    groups = json_as_list[key_to_pos_dict[\"groups\"]][1]\n",
    "\n",
    "    # get the connectors (input and output nodes of groups) and all group connections\n",
    "    connectors = {}\n",
    "    group_connections = {}\n",
    "\n",
    "    for group in groups:\n",
    "        # get the group name\n",
    "        group_name = group[0]\n",
    "        key_to_pos_dict_group = {}\n",
    "        for ind, elem in enumerate(group[1]):\n",
    "            key_to_pos_dict_group[elem[0]] = ind\n",
    "        # get the connectors of this group\n",
    "        connectors[group_name] = group[1][key_to_pos_dict_group[\"connectors\"]][1]\n",
    "        # get the connections of this group and add the group name to the \n",
    "        # object's name\n",
    "        add_group_name_lambda = lambda x: add_group_name(x, group_name)\n",
    "        group_connections_wn = list(map(add_group_name_lambda, group[1][key_to_pos_dict_group[\"connections\"]][1]))\n",
    "        group_connections[group_name] = group_connections_wn\n",
    "\n",
    "    # divide connectors into input and output nodes\n",
    "    group_outputs = []\n",
    "    group_inputs = []\n",
    "\n",
    "    for group in groups:\n",
    "        for connector in connectors[group[0]]:\n",
    "            if connector[1] == 'true':\n",
    "                group_inputs.append((group[0], connector[0]))\n",
    "            else:\n",
    "                group_outputs.append((group[0], connector[0]))\n",
    "\n",
    "    # get all connections to and from group output nodes\n",
    "    group_output_connections = find_connector_connections(group_outputs, \n",
    "                                                          connections_outside_groups,\n",
    "                                                          group_connections)\n",
    "    # replace source -> group_output -> target connections by source -> target connections\n",
    "    replaced_connections = list(map(replace_middle_connection, \n",
    "                                    group_output_connections.values()))\n",
    "    # add the replaced connections to the connection list\n",
    "    _ = [connections_outside_groups.extend(cons) for cons in replaced_connections]\n",
    "\n",
    "    # now do the same for the group input nodes\n",
    "    group_input_connections = find_connector_connections(group_inputs, \n",
    "                                                          connections_outside_groups,\n",
    "                                                          group_connections,\n",
    "                                                          output_nodes=False)\n",
    "    replaced_connections = list(map(replace_middle_connection,\n",
    "                                    group_input_connections.values()))\n",
    "    _ = [connections_outside_groups.extend(cons) for cons in replaced_connections]\n",
    "\n",
    "    # finally add the connections inside the groups now that all connections\n",
    "    # to group input and output nodes have been removed\n",
    "    _ = [connections_outside_groups.extend(cons) for cons in group_connections.values()]\n",
    "\n",
    "    return connections_outside_groups\n",
    "\n",
    "def number_of_connections(con_dict):\n",
    "    length = 0\n",
    "    if type(con_dict) == dict:\n",
    "        for key in con_dict:\n",
    "            length += len(con_dict[key])\n",
    "    elif type(con_dict) == list:\n",
    "        for sublist in con_dict:\n",
    "            length += len(sublist)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_connections = get_all_connections(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "669"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_connections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test simpler JSON file\n",
    "To be sure that everything works correctly I added a small test architecture to the JSON files. It includes all scenarios of different group input and output connections, but with only a few objects to stay on top of things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_arc = read_JSON_as_list('./JSON/test_architecture.json')\n",
    "test_objects = get_all_objects(test_arc)\n",
    "test_connections = get_all_connections(test_arc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Spatial Template\n",
      "Projection\n",
      "Projection 2\n",
      "Spatial Template\n",
      "Group 1.Component Multiply\n",
      "Group 1.Neural Field\n",
      "Group 1.Static Gain\n",
      "Group 2.Gauss Input\n",
      "Group 2.Neural Field 2\n"
     ]
    }
   ],
   "source": [
    "for obj in test_objects:\n",
    "    print(obj[1][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('source', 'Group 2.Neural Field 2.sigmoided activation'),\n",
       "  ('target', 'Projection.input')],\n",
       " [('source', 'Group 2.Neural Field 2.sigmoided activation'),\n",
       "  ('target', 'Projection 2.input')],\n",
       " [('source', 'Linear Spatial Template.spatial pattern'),\n",
       "  ('target', 'Group 1.Component Multiply.operands')],\n",
       " [('source', 'Spatial Template.spatial pattern'),\n",
       "  ('target', 'Group 1.Component Multiply.operands')],\n",
       " [('source', 'Spatial Template.spatial pattern'),\n",
       "  ('target', 'Group 1.Static Gain.input')],\n",
       " [('source', 'Group 1.Neural Field.sigmoided activation'),\n",
       "  ('target', 'Group 2.Neural Field 2.input')],\n",
       " [('source', 'Group 1.Component Multiply.product'),\n",
       "  ('target', 'Group 1.Neural Field.input')],\n",
       " [('source', 'Group 1.Static Gain.output'),\n",
       "  ('target', 'Group 1.Neural Field.input')],\n",
       " [('source', 'Group 2.Gauss Input.Gauss input'),\n",
       "  ('target', 'Group 2.Neural Field 2.input')]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_connections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
